{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "j5XHy7-ppKKV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Open Ai and pinecone initialisation and uploading QA data\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "33Y0r1mXmYrg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bIYx3r7HmWAA"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "from pinecone import Pinecone\n",
        "\n",
        "openai.api_key = 'key'\n",
        "pinecone = Pinecone(api_key='pinecone key', environment='sandbox')  # Replace 'sandbox' with your environment\n",
        "index_name = 'name'  # Replace with  Pinecone index name\n",
        "def index_data_to_pinecone(data):\n",
        "    pinecone.create_index(index_name)\n",
        "    pinecone.upsert_items(index_name, data)\n",
        "your_qa_data = [...]  # Replace with QA data\n",
        "index_data_to_pinecone(your_qa_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Retrieve Answer Candidates Using Pinecone"
      ],
      "metadata": {
        "id": "Gax7RfFvm1d_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def search_pinecone(query_vector, top_k=5):\n",
        "    results = pinecone.query(index_name, query_vector, top_k=top_k)\n",
        "    return results['items']"
      ],
      "metadata": {
        "id": "p8X6D-rcmz7H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ask Question Using OpenAI's API"
      ],
      "metadata": {
        "id": "8kt6mWMVoL6_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ask_question(question, context=''):\n",
        "    prompt = f\"Question: {question}\\nContext: {context}\\nAnswer:\"\n",
        "    response = openai.Completion.create(\n",
        "        model=\"text-davinci-003\", #we can use other models too\n",
        "        prompt=prompt,\n",
        "        temperature=0.7,\n",
        "        max_tokens=150\n",
        "    )\n",
        "    return response.choices[0].text.strip()\n"
      ],
      "metadata": {
        "id": "02xmsaqEoMvV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Combine Pinecone Search and OpenAI Generation"
      ],
      "metadata": {
        "id": "HWDsG7ewocIJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rag_qa_bot(question, context=''):\n",
        "    query_vector = ...  # Convert question to a vector using a suitable method for Example BERT\n",
        "    answer_candidates = search_pinecone(query_vector)\n",
        "\n",
        "    for candidate in answer_candidates:\n",
        "        context_with_candidate = f\"{context} {candidate['text']}\"\n",
        "        generated_answer = ask_question(question, context_with_candidate)\n",
        "\n",
        "        # additional logic can be added to filter the results\n",
        "        if generated_answer:\n",
        "            return generated_answer\n",
        "\n",
        "    return \"I couldn't find an answer.\"\n",
        "\n",
        "user_question = \"What is the revenue of our company?\"\n",
        "user_context = \"Our company is a leading tech firm specializing in software development.\"\n",
        "\n",
        "answer = rag_qa_bot(user_question, user_context)\n",
        "print(\"Answer:\", answer)\n"
      ],
      "metadata": {
        "id": "AxsN0H1codO9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}